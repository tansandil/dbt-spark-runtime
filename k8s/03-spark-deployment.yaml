apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark
  namespace: dn-dbt-spark
  labels:
    app: spark
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark
  template:
    metadata:
      labels:
        app: spark
    spec:
      serviceAccountName: spark
      containers:
      - name: spark-thrift-server
        image: apache/spark:3.5.0-scala2.12-java11-python3-ubuntu
        command: ["/opt/spark/sbin/start-thriftserver.sh"]
        env:
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        - name: SPARK_LOCAL_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        args:
        - --conf
        - spark.sql.hive.thriftServer.singleSession=false
        - --conf
        - spark.sql.warehouse.dir=/tmp/spark-warehouse
        - --conf
        - spark.master=k8s://https://kubernetes.default.svc:443
        - --conf
        - spark.kubernetes.container.image=apache/spark:3.5.0-scala2.12-java11-python3-ubuntu
        - --conf
        - spark.kubernetes.namespace=dn-dbt-spark
        - --conf
        - spark.kubernetes.authenticate.driver.serviceAccountName=spark
        - --conf
        - spark.kubernetes.executor.deleteOnTermination=true
        - --conf
        - spark.dynamicAllocation.enabled=true
        - --conf
        - spark.dynamicAllocation.initialExecutors=0
        - --conf
        - spark.dynamicAllocation.minExecutors=0
        - --conf
        - spark.dynamicAllocation.maxExecutors=5
        - --conf
        - spark.dynamicAllocation.executorIdleTimeout=60s
        - --conf
        - spark.executor.memory=1g
        - --conf
        - spark.executor.cores=1
        - --conf
        - spark.driver.memory=1g
        - --conf
        - spark.driver.host=$(SPARK_LOCAL_IP)
        - --conf
        - spark.driver.bindAddress=0.0.0.0
        - --hiveconf
        - hive.server2.thrift.port=10000
        - --hiveconf
        - hive.server2.thrift.bind.host=0.0.0.0
        ports:
        - name: thrift
          containerPort: 10000
        - name: spark-ui
          containerPort: 4040
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "3Gi"
            cpu: "1500m"
        readinessProbe:
          tcpSocket:
            port: 10000
          initialDelaySeconds: 60
          periodSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 10000
          initialDelaySeconds: 120
          periodSeconds: 30
---
apiVersion: v1
kind: Service
metadata:
  name: spark
  namespace: dn-dbt-spark
spec:
  type: ClusterIP
  ports:
  - port: 10000
    targetPort: 10000
  selector:
    app: spark
    